分别介绍两种生存分析，批量logrank检验，批量Cox回归（就是批量单因素分析）。

用TCGA-COAD的数据演示，批量进行约2万个基因的生存分析。

## 数据准备

首先用我的1行代码整理表达矩阵和临床信息，会自动得到6个表达矩阵（mRNA和lncRNA的counts/fpkm/tpm）和临床信息，这样得到的表达矩阵的样本顺序和临床信息的顺序自动就是一致的，不需要再次整理。

- [1行代码提取6种TCGA表达矩阵和临床信息](https://mp.weixin.qq.com/s/1OBGjUKnGyiALmLafYNPUQ)            
- [1行代码提取6种TCGA表达矩阵2.0版](https://mp.weixin.qq.com/s/QFGCtrIeaAIichovw6OBVw)
- [1行代码提取TCGA的6种表达矩阵是有视频教程的](https://mp.weixin.qq.com/s/u6VkBcYqakZkaNXjzNTZcw)


```r
library(SummarizedExperiment)
library(tidyverse)
library(TCGAbiolinks)

source("getTCGAexpr.r") # 1行代码脚本，代码获取请翻看推文

getTCGAexpr("TCGA-COAD")
```

我们选用mRNA的counts矩阵，先用`DESeq2`的`vst`函数处理下。


```r
rm(list = ls())

# 加载整理好的表达矩阵和临床信息
load(file = "G:/tcga/output_expr/TCGA-COAD_clinical.rdata")
load(file = "G:/tcga/output_expr/TCGA-COAD_mrna_expr_counts.rdata")

# 顺序一致
identical(colnames(mrna_expr_counts), rownames(clin_info))
## [1] TRUE
```

TCGA的数据直接进行生存分析有很多问题，在进行批量生存分析前，我们还要做一些数据预处理工作，这些不是必须的，也没有标准，大家根据自己的需求来！（但是你不做这些在进行批量生存分析时就会遇到各种报错）

比如以下问题：

- counts/tpm/fpkm/rmse，到底用哪一种？我这里用的是vst后的数据，很多文献里用的是log2(tpm+1)，也有用log2(fpkm+1)的，还有用log2(count+1)的！所以别纠结！通常用的比较多的是log2(tpm+1)。

你看这篇cell的文章（doi:10.1016/j.cell.2018.03.052）用的就是vst后的数据：
![doi:10.1016/j.cell.2018.03.052.](https://aliyun-bucket0324.oss-cn-shanghai.aliyuncs.com/img/image-20221229100729382.png)

关于counts/tpm/fpkm/vst/cpm的区别，我也专门写了两篇推文进行介绍：
- [DESeq2差异分析及VST变换的探索](https://mp.weixin.qq.com/s/CBznByKNGwPEKIKM5U0Oyw)
- [count、tpm、fpkm、vst、cpm的表达量差异](https://mp.weixin.qq.com/s/aff-AX9aA2tSDa2zbB8ZRQ)

除此之外，还要注意以下问题：
- 要不要先进行log/标准化呢？看你用的是哪种数据，vst是不需要的~
- 表达量非常低的基因，有的基因在多个样本表达量都一样，这种都会导致方差太小，根据表达量进行分组时会有问题，要去掉；
- 还需要去除正常的样本，我这里只对肿瘤样本进行生存分析；
- 有时多个样本，可能是同一个人的，这种情况，需不需要去重复呢？为了省事，这种情况我没做处理，最好去重；
- 临床信息中随访时间可能存在负值！需要去除，某些样本随访时间和结局可能同时缺失，也要去除！
- 单因素cox回归，不符合PH假设，能不能用呢？好像实际做的时候没几篇文章讨论这个问题......


```r
# 根据列名的第14,15位数判断，小于10 就是tumor
keep_samples <- as.numeric(substr(colnames(mrna_expr_counts),14,15))<10

# 41个normal，480个tumor
table(keep_samples)
## keep_samples
## FALSE  TRUE 
##    41   480

exprset <- mrna_expr_counts[,keep_samples]

# 临床信息只要两列就够了：生存时间和生存状态
clin <- clin_info[keep_samples, c("days_to_last_follow_up","vital_status")] 
names(clin) <- c("time","event")

dim(exprset)
## [1] 19938   480
dim(clin)
## [1] 480   2

identical(colnames(exprset),rownames(clin))
## [1] TRUE
```

然后是过滤掉低表达基因，方差小于1的我都去掉了，你可以试试其他阈值，没有统一标准~


```r
#exprset <- exprset[!rowSums(exprset) < 0.1*480, ]
exprset <- exprset[!apply(exprset,1,var) < 1,]

dim(exprset) # 还剩18443个基因
## [1] 18443   480
```

去掉没有生存结局的：


```r
# 2个样本没有结局，去掉
table(is.na(clin$event))
## 
## FALSE  TRUE 
##   478     2

drop <- is.na(clin$event)
clin <- clin[!drop,]

table(is.na(clin$event))
## 
## FALSE 
##   478

exprset <- exprset[,!drop]

# 没有生存时间小于0的，46个生存时间是NA
table(is.na(clin$time))
## 
## FALSE  TRUE 
##   432    46
table(clin$time<0)
## 
## FALSE 
##   432

# 最后把生存结局用0,1表示
clin$event <- ifelse(clin$event == "Dead",1,0)
```

最终剩余18443个基因，478个样本。


```r
dim(clin)
## [1] 478   2
dim(exprset)
## [1] 18443   478

identical(colnames(exprset),rownames(clin))
## [1] TRUE

#save(exprset, clin,file = "output_expr/batch_survival.rdata")
```

基本上做过这些过滤后，你再进行生存分析不容易遇到很多小问题，当然你也可以完全不进行过滤，直接进行生存分析，没有标准！

## 批量logrank检验

你可以手撕代码解决，这也是目前绝大多数教程的做法。手撕代码又可以有apply系列，for循环系列，purrr系列等，大同小异，殊途同归，条条大路通罗马！

我这里就用`apply`了：


```r
rm(list = ls())
load(file = "G:/tcga/output_expr/batch_survival_vst.rdata")
library(survival)

logrank_res <- apply(exprset, 1, function(x){
    surv <- Surv(clin$time, clin$event)
    group <- ifelse(x > median(x),"high","low") # 根据表达量的中位数分组
    fit <- survdiff(surv ~ group)
    pvalue <- 1-pchisq(fit$chisq, df=1)
  })

res.logrank <- data.frame(gene_symbol = rownames(exprset), pvalue = logrank_res)
res.logrank <- res.logrank[order(res.logrank$pvalue),]
#save(res.logrank, file = "G:/tcga/output_expr/batch_logrank_res_vst.rdata")
```

查看结果：


```r
psych::headTail(res.logrank)
##          gene_symbol pvalue
## DPP7            DPP7      0
## HCN2            HCN2      0
## COLGALT2    COLGALT2      0
## KIAA0825    KIAA0825      0
## ...             <NA>    ...
## RGPD1          RGPD1      1
## TMEM129      TMEM129      1
## MICAL3        MICAL3      1
## ZNF365        ZNF365      1

table(res.logrank$pvalue<0.05) # 比直接用tpm少了400个左右
## 
## FALSE  TRUE 
## 17184  1405
```

随便找个基因试试看：


```r
group <- ifelse(t(exprset)[,"HCN2"] >median(t(exprset)[,"HCN2"]),"high","low")
df.tmp <- data.frame(time = clin$time,event=clin$event,group=c(group))

# logrank检验和批量的结果一样
survdiff(Surv(time,event)~group, data = df.tmp)
## Call:
## survdiff(formula = Surv(time, event) ~ group, data = df.tmp)
## 
## n=432, 46 observations deleted due to missingness.
## 
##              N Observed Expected (O-E)^2/E (O-E)^2/V
## group=high 214       42     25.6     10.52      19.7
## group=low  218       16     32.4      8.31      19.7
## 
##  Chisq= 19.7  on 1 degrees of freedom, p= 9e-06
```


```r
# 画个图看看
library(survminer)
## Loading required package: ggpubr
## 
## Attaching package: 'survminer'
## The following object is masked from 'package:survival':
## 
##     myeloma
f <- survfit(Surv(time,event)~group, data = df.tmp)
ggsurvplot(f,pval = T,palette = "jama")
```

![](https://aliyun-bucket0324.oss-cn-shanghai.aliyuncs.com/img/unnamed-chunk-10-169001711.png)

效果很不错！


## 批量Cox单因素分析

单因素Cox回归，有两种思路：
1. 你可以根据表达量高低把样本分为两组，然后进行Cox分析；
2. 也可以直接把表达量作为连续性变量进行Cox分析，这样的结果解释起来就完全不一样了！

你在进行多因素分析时，是继续分成2组进行，还是直接用表达量呢？

我的看法是分成两组更合适，如果是直接用连续性数值进行分析，结果的解释是自变量每增加一个单位，风险增加多少倍，这对一个基因来说有点扯，比如表达量从5变成6，患癌症的风险增加3倍，你觉得真实吗？

而变成两组后，结果的解释是高表达组的风险是低表达组的风险的多少倍，这样就合理多了。但是这个也没有标准，你随便用，只要能解释得通。

数据还是用之前批量logrank检验的数据，是TCGA-COAD的数据，进行了一些数据预处理。


```r
rm(list = ls())
load(file = "G:/tcga/output_expr/batch_survival_vst.rdata")
library(survival)
```

我这里借用了`broom`包，帮我自动提取回归系数、HR值、HR值的95%的可信区间、P值，没安装的需要先安装。


```r
cox_res <- apply(exprset, 1, function(x){
    surv <- Surv(clin$time, clin$event)
    group <- ifelse(x > median(x),"high","low") # 根据表达量的中位数分组
    fit <- coxph(surv ~ group)
    tmp <- broom::tidy(fit,exponentiate = T, conf.int = T)
  })

res.cox <- do.call(rbind, cox_res)
res.cox$gene_symbol <- rownames(exprset)

#save(res.cox, file = "G:/tcga/output_expr/batch_cox_res_vst.rdata")
```

查看结果：


```r
psych::headTail(res.cox)
##       term estimate std.error statistic p.value conf.low conf.high gene_symbol
## 1 grouplow     1.04      0.26      0.16    0.87     0.62      1.75      MT-CO1
## 2 grouplow     1.09      0.27      0.31    0.76     0.65      1.82      MT-ND4
## 3 grouplow     1.15      0.27      0.54    0.59     0.68      1.95      MT-CO2
## 4 grouplow     1.07      0.27      0.27    0.79     0.64      1.81      MT-CO3
## 5     <NA>      ...       ...       ...     ...      ...       ...        <NA>
## 6 grouplow     2.32      1.01      0.84     0.4     0.32     16.79       OR2F2
## 7 grouplow     3.09      1.01      1.12    0.26     0.43      22.4       ZNRF4
## 8 grouplow     0.32      0.73     -1.57    0.12     0.08      1.33 RPS10-NUDT3
## 9 grouplow     1.05      1.01      0.05    0.96     0.15      7.64       IQCF2
```

`estimate`：HR值（exp(coef)）
`std.error`：回归系数的标准误（se(coef)）
`statistic`：Wald检验的z值
`p.value`：回归系数的P值
`conf.low/conf.high`：HR的95%的可信区间

可以看到这里的`term`项都是`grouplow`，所以结果解释是低表达组相比于高表达组怎么怎么样，如果你想改，就在上面的代码中把`group`变成因子，自定义level即可。


```r
table(res.cox$p.value<0.05) # 和logrank结果非常接近
## 
## FALSE  TRUE 
## 17244  1345
```

两种方法的结果画个维恩图看看：


```r
load(file = "G:/tcga/output_expr/batch_logrank_res_vst.rdata")
```


```r
logrank <- res.logrank$gene_symbol[res.logrank$pvalue<0.05]
cox <- res.cox$gene_symbol[res.cox$p.value<0.05]

library(VennDiagram)
## Loading required package: grid
## Loading required package: futile.logger
## 
## Attaching package: 'VennDiagram'
## The following object is masked from 'package:ggpubr':
## 
##     rotate

l <- list(logrank = logrank, cox=cox)

venn.diagram(l,filename = "loagran_cox.png",
                   alpha=c(0.8, 0.8),
                   fill=c("#0073C2FF","#EFC000FF"))
## [1] 1
```

![](https://aliyun-bucket0324.oss-cn-shanghai.aliyuncs.com/img/984165165461.png)

竟然完美重合！
